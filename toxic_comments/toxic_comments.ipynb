{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Введение\" data-toc-modified-id=\"Введение-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Введение</a></span><ul class=\"toc-item\"><li><span><a href=\"#План-работы\" data-toc-modified-id=\"План-работы-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>План работы</a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Предобработка данных</a></span></li><li><span><a href=\"#Подготовка-данных-для-обучения-модели\" data-toc-modified-id=\"Подготовка-данных-для-обучения-модели-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Подготовка данных для обучения модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-текстов-для-модели-линейной-регрессии\" data-toc-modified-id=\"Подготовка-текстов-для-модели-линейной-регрессии-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Подготовка текстов для модели линейной регрессии</a></span></li><li><span><a href=\"#Подготовка-текстов-для-модели-решающего-дерева-и-градиентного-бустинга\" data-toc-modified-id=\"Подготовка-текстов-для-модели-решающего-дерева-и-градиентного-бустинга-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Подготовка текстов для модели решающего дерева и градиентного бустинга</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Модель-логистической-регрессии\" data-toc-modified-id=\"Модель-логистической-регрессии-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Модель логистической регрессии</a></span></li><li><span><a href=\"#Модель-случайного-дерева\" data-toc-modified-id=\"Модель-случайного-дерева-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Модель случайного дерева</a></span></li><li><span><a href=\"#Модель-градиентного-бустинга-LightGBM\" data-toc-modified-id=\"Модель-градиентного-бустинга-LightGBM-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Модель градиентного бустинга LightGBM</a></span></li><li><span><a href=\"#Вывод-по-итогам-обучения\" data-toc-modified-id=\"Вывод-по-итогам-обучения-3.0.4\"><span class=\"toc-item-num\">3.0.4&nbsp;&nbsp;</span>Вывод по итогам обучения</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Тестирование модели</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целью проекта является выбрать и обучить модель для классификации комментариев (позитивные/негативные) со значением метрики качества F1 не менее 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выполнении проекта сравним модели с помощью TF-IDF, c помощью языковых представлений без и с использованием BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа будет выполняться согласно следующего плана:\n",
    "- загрузка и предобработка данных\n",
    "- подготовка данных для обучения моделей\n",
    "- обучение моделей с различными гиперпараметрами и выбор оптимальной методом кросс-валидации\n",
    "- тестирование модели на тестовой выборке и оценка ее адекватности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = 'toxic_comments.csv'\n",
    "server_path = '/datasets/toxic_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(local_path):\n",
    "    data = pd.read_csv(local_path)\n",
    "else:\n",
    "    data = pd.read_csv(server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала, рассмотрим имеющийся датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.info())\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из представленной выше информации, в датасете есть три столбца - `Unnamed: 0`, повторяющий индекс, `text` - текст комментария, `toxic` - категориальный признак, описывающий, является ли комментарий негативным.\n",
    "Всего в датасете представлено почти 160 000 объектов.\n",
    "Пропуски в датасете отсутствуют.\n",
    "\n",
    "Проверим датасет на наличие дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим ненужный столбец, повторяющий индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с подготовки текстов для дальнейшего обучения.\n",
    "Для начала очистим текст от знаков препинания и стоп-слов, а так же лемматизируем имеющиеся в тексте слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_n = re.compile('\\n')\n",
    "clean_text = re.compile(\"(?!')[\\W\\d]+|(?![\\w])' \")\n",
    "\n",
    "stopwords_list = list(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = del_n.sub(' ', str(text).lower())\n",
    "    res_text = clean_text.sub(' ', text)\n",
    "    return res_text\n",
    "\n",
    "def del_stopwords(text):\n",
    "    clean_tokens = tuple(\n",
    "        map( lambda x: x if x not in stopwords_list else '', word_tokenize(text) )\n",
    "    )\n",
    "    res_text = ' '.join(clean_tokens)\n",
    "    return res_text\n",
    "\n",
    "def prepare(text):\n",
    "    clean_text = clean(text)\n",
    "    no_sw_text = del_stopwords(clean_text)\n",
    "    return no_sw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402c9efef6fe4ad493714e0834af178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['clean_text'] = data['text'].progress_apply(prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469fe2cb002d48b68a07b6c890140b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemm_texts = []\n",
    "total = data.shape[0]\n",
    "nlp_pipe = nlp.pipe(data['clean_text'].values, disable=['ner', 'parser'])\n",
    "\n",
    "for doc in tqdm(nlp_pipe, total=total):\n",
    "    lemm_text = ' '.join([token.lemma_ for token in doc])\n",
    "    lemm_texts.append(lemm_text)\n",
    "    \n",
    "data['text_lemms'] = lemm_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation   edits made   username hardcore m...</td>\n",
       "      <td>explanation    edit make    username hardcore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww  matches  background colour  'm seemingl...</td>\n",
       "      <td>d'aww   match   background colour   ' m seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  'm really  trying  edit war  's    gu...</td>\n",
       "      <td>hey man   ' m really   try   edit war   's    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make  real suggestions  improvement  ...</td>\n",
       "      <td>can not make   real suggestion   improvemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir   hero  chance  remember  page  's</td>\n",
       "      <td>sir    hero   chance   remember   page   's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations    well use  tools well talk</td>\n",
       "      <td>congratulation     well use   tool well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker   piss around   work</td>\n",
       "      <td>cocksucker    piss around    work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism   matt shirvington article   revert...</td>\n",
       "      <td>vandalism    matt shirvington article    rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry   word nonsense  offensive   anyway  'm ...</td>\n",
       "      <td>sorry    word nonsense   offensive    anyway  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment   subject    contrary    dulithgow</td>\n",
       "      <td>alignment    subject     contrary     dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  explanation   edits made   username hardcore m...   \n",
       "1  d'aww  matches  background colour  'm seemingl...   \n",
       "2  hey man  'm really  trying  edit war  's    gu...   \n",
       "3    ca n't make  real suggestions  improvement  ...   \n",
       "4            sir   hero  chance  remember  page  's    \n",
       "5       congratulations    well use  tools well talk   \n",
       "6                    cocksucker   piss around   work   \n",
       "7   vandalism   matt shirvington article   revert...   \n",
       "8  sorry   word nonsense  offensive   anyway  'm ...   \n",
       "9       alignment   subject    contrary    dulithgow   \n",
       "\n",
       "                                          text_lemms  \n",
       "0  explanation    edit make    username hardcore ...  \n",
       "1  d'aww   match   background colour   ' m seemin...  \n",
       "2  hey man   ' m really   try   edit war   's    ...  \n",
       "3     can not make   real suggestion   improvemen...  \n",
       "4        sir    hero   chance   remember   page   's  \n",
       "5       congratulation     well use   tool well talk  \n",
       "6                  cocksucker    piss around    work  \n",
       "7    vandalism    matt shirvington article    rev...  \n",
       "8  sorry    word nonsense   offensive    anyway  ...  \n",
       "9    alignment    subject     contrary     dulithgow  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак и признак, по которому будет проводиться обучение и дальнейшее предсказывание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text_lemms']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на тренировочную и тестовую. Для того, чтобы большее количество текстов было использовано при обучении, оставим для теста 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test =\\\n",
    "train_test_split(features, target, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка текстов для модели линейной регрессии "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка текстов для модели решающего дерева и градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вышеупомянутых моделей используем библиотеку word2vec для векторизации текстов. Судя по первым 10 комментариям, лучше всего использовать модель, обученную на постах в твиттере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим pipeline для предобработки текстов с помощью TF-IDF и дальнейшего обучения модели логистической регрессии, чтобы обеспечить выбор оптимальных параметров для TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pipeline = Pipeline(\n",
    "    steps = [('tfidf', TfidfVectorizer() ),('log_reg',LogisticRegression() )]\n",
    ")\n",
    "\n",
    "log_reg_param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__sublinear_tf': [False, True],\n",
    "    'log_reg__penalty': ['l2', None],\n",
    "    'log_reg__C': np.arange (5.0, 15.0, 0.5),\n",
    "    \"log_reg__max_iter\": [10000000],\n",
    "    \"log_reg__random_state\": [RANDOM_STATE]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_best_model = RandomizedSearchCV(\n",
    "    log_reg_pipeline,\n",
    "    log_reg_param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;log_reg&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;log_reg__C&#x27;: array([ 5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ,\n",
       "       10.5, 11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5]),\n",
       "                                        &#x27;log_reg__max_iter&#x27;: [10000000],\n",
       "                                        &#x27;log_reg__penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                                        &#x27;log_reg__random_state&#x27;: [12345],\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                                        &#x27;tfidf__sublinear_tf&#x27;: [False, True]},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;log_reg&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;log_reg__C&#x27;: array([ 5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ,\n",
       "       10.5, 11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5]),\n",
       "                                        &#x27;log_reg__max_iter&#x27;: [10000000],\n",
       "                                        &#x27;log_reg__penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                                        &#x27;log_reg__random_state&#x27;: [12345],\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)],\n",
       "                                        &#x27;tfidf__sublinear_tf&#x27;: [False, True]},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;log_reg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('log_reg',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'log_reg__C': array([ 5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ,\n",
       "       10.5, 11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5]),\n",
       "                                        'log_reg__max_iter': [10000000],\n",
       "                                        'log_reg__penalty': ['l2', None],\n",
       "                                        'log_reg__random_state': [12345],\n",
       "                                        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
       "                                        'tfidf__sublinear_tf': [False, True]},\n",
       "                   random_state=12345, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_best_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7817550461827532"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_best_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии показала значение метрики F1, превышающее пороговое значение (0.78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры случайного дерева будем подбирать с помощью RandomizedSearchCV.\n",
    "При обучении и предсказании будет использоваться корпус текстов, приведенных в векторный вид с помощью модели word2vec `glove twitter 50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_words = set(wv_model.index_to_key)\n",
    "\n",
    "def get_average_vector(word_list, model, valid_words):\n",
    "    vectors = [model[word] for word in word_list if word in valid_words]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return np.zeros(model.vector_size, dtype=float)\n",
    "\n",
    "wv_corpus_train_avg = [get_average_vector(ls, wv_model, valid_words) for ls in features_train]\n",
    "\n",
    "wv_corpus_test_avg = [get_average_vector(ls, wv_model, valid_words) for ls in features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(wv_model.index_to_key )\n",
    " \n",
    "wv_corpus_train = np.array([np.array([wv_model[i] for i in ls if i in words])\n",
    "                         for ls in features_train])\n",
    "wv_corpus_test = np.array([np.array([wv_model[i] for i in ls if i in words])\n",
    "                         for ls in features_test])\n",
    "\n",
    "\n",
    "wv_corpus_train_avg = []\n",
    "for v in wv_corpus_train:\n",
    "    if v.size:\n",
    "        wv_corpus_train_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        wv_corpus_train_avg.append(np.zeros(50, dtype=float))\n",
    "        \n",
    "wv_corpus_test_avg = []\n",
    "for v in wv_corpus_test:\n",
    "    if v.size:\n",
    "        wv_corpus_test_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        wv_corpus_test_avg.append(np.zeros(50, dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "В целом подход, который ты попробовал имеет право на жизнь - получение эмбеддинга текста как среднее для эмбединга отдельных слов. Здесь есть те же самые недостатки, как и в подходе мешка слов - мы не учитываем порядок слов.\n",
    "    \n",
    "До появления трансформеров использование w2vec + рекурентных нейронных сетей это был основной подход для работы с текстами.    \n",
    " \n",
    "Подводя резюме: с точки зрения освоения нового инструментария в учебном проекте - все сделано круто.  Но эффективность такой подход показывает заметно ниже, чем банальный TF-IDF и  тем более трансформеры.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "forest_model_params = {\n",
    "    'n_estimators' : range(10,50,10),\n",
    "    'max_depth' : [None] + [i for i in range(2, 7)],\n",
    "    'min_samples_split' : range(2, 11, 5),\n",
    "    'min_samples_leaf' : range(1,11,5),\n",
    "    'max_features' : [1, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_forest_model = RandomizedSearchCV(\n",
    "    random_forest_model,\n",
    "    forest_model_params,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(random_state=12345),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 2, 3, 4, 5, 6],\n",
       "                                        &#x27;max_features&#x27;: [1, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(1, 11, 5),\n",
       "                                        &#x27;min_samples_split&#x27;: range(2, 11, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50, 10)},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(random_state=12345),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 2, 3, 4, 5, 6],\n",
       "                                        &#x27;max_features&#x27;: [1, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(1, 11, 5),\n",
       "                                        &#x27;min_samples_split&#x27;: range(2, 11, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50, 10)},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=12345)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(random_state=12345),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 2, 3, 4, 5, 6],\n",
       "                                        'max_features': [1, 'sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(1, 11, 5),\n",
       "                                        'min_samples_split': range(2, 11, 5),\n",
       "                                        'n_estimators': range(10, 50, 10)},\n",
       "                   random_state=12345, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_model.fit(wv_corpus_train_avg, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22725980175091393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса на преобразованных в векторы словах показала гораздо более худший результат, чем пороговое значение и модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель градиентного бустинга LightGBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве еще одной модели рассмотрим модель градиентного бустинга LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lgb_params = {\n",
    "    'num_leaves' : range(10,100,10),\n",
    "    'max_depth' : range(7,15,1),\n",
    "    'n_estimators' : range(100,1000,100),\n",
    "}\n",
    "\n",
    "best_lgb_model = RandomizedSearchCV(\n",
    "    lgb_model,\n",
    "    lgb_params,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   5.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   6.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=  34.8s\n",
      "[CV] END max_depth=6, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=20; total time=   1.3s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=  30.5s\n",
      "[CV] END max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   4.1s\n",
      "[CV] END max_depth=4, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   2.1s\n",
      "[CV] END max_depth=4, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=  28.9s\n",
      "[CV] END max_depth=4, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=10; total time=  11.3s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=  12.2s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   4.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=20; total time=  15.5s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=   5.4s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   7.0s\n",
      "[CV] END max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   2.2s\n",
      "[CV] END max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   2.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   2.2s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   7.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=10; total time=   8.4s\n",
      "[CV] END max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=   9.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=10; total time=   3.0s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=10; total time=   1.3s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   7.8s\n",
      "[CV] END max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=20; total time=   5.2s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   0.8s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   0.7s\n",
      "[CV] END ......max_depth=11, n_estimators=300, num_leaves=90; total time=   6.5s\n",
      "[CV] END .......max_depth=7, n_estimators=700, num_leaves=30; total time=   8.7s\n",
      "[CV] END .......max_depth=9, n_estimators=700, num_leaves=10; total time=   7.7s\n",
      "[CV] END ......max_depth=11, n_estimators=900, num_leaves=90; total time=  22.3s\n",
      "[CV] END .......max_depth=9, n_estimators=400, num_leaves=80; total time=  10.1s\n",
      "[CV] END ......max_depth=14, n_estimators=700, num_leaves=80; total time=  14.6s\n",
      "[CV] END ......max_depth=14, n_estimators=800, num_leaves=70; total time=  17.6s\n",
      "[CV] END .......max_depth=8, n_estimators=400, num_leaves=40; total time=   5.9s\n",
      "[CV] END .......max_depth=7, n_estimators=100, num_leaves=50; total time=   2.8s\n",
      "[CV] END .......max_depth=7, n_estimators=100, num_leaves=50; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   5.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   6.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=  35.4s\n",
      "[CV] END max_depth=6, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=20; total time=   1.3s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.8s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.8s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   8.6s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   8.8s\n",
      "[CV] END max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   4.2s\n",
      "[CV] END max_depth=4, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   2.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=  29.0s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   1.1s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   1.1s\n",
      "[CV] END max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   7.5s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=  12.0s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=   7.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=20; total time=  15.6s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   2.4s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=   5.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   7.0s\n",
      "[CV] END max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   2.3s\n",
      "[CV] END max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   2.2s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   8.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=  15.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=10; total time=   7.5s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=   8.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=10; total time=   3.0s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   7.2s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=10; total time=   1.3s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   8.1s\n",
      "[CV] END max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=  10.6s\n",
      "[CV] END ......max_depth=11, n_estimators=300, num_leaves=90; total time=   6.6s\n",
      "[CV] END .......max_depth=7, n_estimators=700, num_leaves=30; total time=  10.0s\n",
      "[CV] END ......max_depth=10, n_estimators=700, num_leaves=80; total time=  16.0s\n",
      "[CV] END ......max_depth=10, n_estimators=800, num_leaves=30; total time=  12.3s\n",
      "[CV] END .......max_depth=9, n_estimators=400, num_leaves=80; total time=  10.1s\n",
      "[CV] END ......max_depth=14, n_estimators=700, num_leaves=80; total time=  14.8s\n",
      "[CV] END ......max_depth=14, n_estimators=800, num_leaves=70; total time=  17.2s\n",
      "[CV] END .......max_depth=8, n_estimators=400, num_leaves=40; total time=   5.8s\n",
      "[CV] END ......max_depth=12, n_estimators=600, num_leaves=40; total time=   8.6s\n",
      "[CV] END ......max_depth=11, n_estimators=900, num_leaves=40; total time=  16.2s\n",
      "[CV] END ......max_depth=13, n_estimators=600, num_leaves=80; total time=  14.0s\n",
      "[CV] END .......max_depth=9, n_estimators=900, num_leaves=60; total time=  16.2s\n",
      "[CV] END ......max_depth=14, n_estimators=300, num_leaves=40; total time=   5.4s\n",
      "[CV] END ......max_depth=13, n_estimators=500, num_leaves=20; total time=   5.9s\n",
      "[CV] END .......max_depth=7, n_estimators=200, num_leaves=20; total time=   3.0s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=40; total time=   5.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=  36.0s\n",
      "[CV] END max_depth=6, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=20; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=  31.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   9.7s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=   1.2s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=   1.2s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   0.9s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=10; total time=   4.1s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=10; total time=   4.7s\n",
      "[CV] END max_depth=4, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   1.3s\n",
      "[CV] END max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   7.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=10; total time=  12.5s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=   7.7s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_leaf=6, min_samples_split=2, n_estimators=30; total time=   4.7s\n",
      "[CV] END max_depth=3, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   1.7s\n",
      "[CV] END max_depth=2, max_features=1, min_samples_leaf=1, min_samples_split=7, n_estimators=10; total time=   0.4s\n",
      "[CV] END max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   2.6s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=30; total time=   6.7s\n",
      "[CV] END max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   2.3s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   2.2s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=20; total time=   8.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=10; total time=   9.1s\n",
      "[CV] END max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=30; total time=   9.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=10; total time=   3.5s\n",
      "[CV] END max_depth=3, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=10; total time=   1.4s\n",
      "[CV] END max_depth=3, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=10; total time=   1.5s\n",
      "[CV] END max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=20; total time=   7.5s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=40; total time=   8.3s\n",
      "[CV] END max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=40; total time=  10.6s\n",
      "[CV] END ......max_depth=11, n_estimators=300, num_leaves=90; total time=   6.5s\n",
      "[CV] END .......max_depth=9, n_estimators=200, num_leaves=70; total time=   4.1s\n",
      "[CV] END .......max_depth=9, n_estimators=700, num_leaves=10; total time=   7.8s\n",
      "[CV] END ......max_depth=11, n_estimators=900, num_leaves=90; total time=  22.6s\n",
      "[CV] END ......max_depth=10, n_estimators=800, num_leaves=30; total time=  12.1s\n",
      "[CV] END ......max_depth=13, n_estimators=100, num_leaves=90; total time=   3.5s\n",
      "[CV] END ......max_depth=14, n_estimators=700, num_leaves=80; total time=  15.1s\n",
      "[CV] END ......max_depth=14, n_estimators=500, num_leaves=50; total time=  10.3s\n",
      "[CV] END ......max_depth=11, n_estimators=100, num_leaves=60; total time=   3.4s\n",
      "[CV] END .......max_depth=8, n_estimators=100, num_leaves=70; total time=   2.6s\n",
      "[CV] END .......max_depth=8, n_estimators=400, num_leaves=40; total time=   5.5s\n",
      "[CV] END ......max_depth=12, n_estimators=600, num_leaves=40; total time=   9.0s\n",
      "[CV] END ......max_depth=11, n_estimators=900, num_leaves=40; total time=  15.7s\n",
      "[CV] END ......max_depth=14, n_estimators=900, num_leaves=20; total time=  11.3s\n",
      "[CV] END .......max_depth=9, n_estimators=900, num_leaves=60; total time=  16.9s\n",
      "[CV] END ......max_depth=14, n_estimators=300, num_leaves=40; total time=   5.1s\n",
      "[CV] END ......max_depth=13, n_estimators=500, num_leaves=20; total time=   5.7s\n",
      "[CV] END .......max_depth=7, n_estimators=200, num_leaves=20; total time=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=LGBMClassifier(random_state=12345), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(7, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(100, 1000, 100),\n",
       "                                        &#x27;num_leaves&#x27;: range(10, 100, 10)},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=LGBMClassifier(random_state=12345), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(7, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(100, 1000, 100),\n",
       "                                        &#x27;num_leaves&#x27;: range(10, 100, 10)},\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=12345)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=12345)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=LGBMClassifier(random_state=12345), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(7, 15),\n",
       "                                        'n_estimators': range(100, 1000, 100),\n",
       "                                        'num_leaves': range(10, 100, 10)},\n",
       "                   random_state=12345, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgb_model.fit(wv_corpus_train_avg, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30375948193120317"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgb_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель градиентного бустинга LightGBM показала результат, лучший чем модель решающего дерева, но гораздо ниже логистической регрессии и порогового значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по итогам обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам обучения была выбрана модель линейной регрессии с предобработкой текстов с помощью TF-IDF.\n",
    "Значение метрики F1 для данной связки составило 0.78, что является самой высокой из всех проанализированных моделей и превосходит пороговое значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = log_reg_best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)),\n",
       "                (&#x27;log_reg&#x27;,\n",
       "                 LogisticRegression(C=9.0, max_iter=10000000,\n",
       "                                    random_state=12345))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)),\n",
       "                (&#x27;log_reg&#x27;,\n",
       "                 LogisticRegression(C=9.0, max_iter=10000000,\n",
       "                                    random_state=12345))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=9.0, max_iter=10000000, random_state=12345)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)),\n",
       "                ('log_reg',\n",
       "                 LogisticRegression(C=9.0, max_iter=10000000,\n",
       "                                    random_state=12345))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики F1 наилучшей модели для тестовой выборки составило: 0.78005657708628\n"
     ]
    }
   ],
   "source": [
    "f1_log_reg = f1_score(target_test, predictions)\n",
    "\n",
    "print(f'Значение метрики F1 наилучшей модели для тестовой выборки составило: {f1_log_reg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполненной работы, лучшей моделью оказалась связка из обработки текстов с помощью TF-IDF и модели логистической регресии. Кроме нее, были рассмотрены модели случайного леса и LightGBM, обучение которых проходило на текстах, преобразованных в векторы с помощью модели, обученной на постах Твиттера.\n",
    "\n",
    "На тестовой выборке лучшая модель показала значение метрики F1, равное 0.78."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 13821,
    "start_time": "2023-08-24T11:04:01.400Z"
   },
   {
    "duration": 6598,
    "start_time": "2023-08-24T11:04:15.224Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-24T11:04:21.824Z"
   },
   {
    "duration": 1063,
    "start_time": "2023-08-24T11:04:21.832Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-24T11:04:22.897Z"
   },
   {
    "duration": 280,
    "start_time": "2023-08-24T11:04:22.951Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-24T11:04:23.233Z"
   },
   {
    "duration": 943,
    "start_time": "2023-08-24T11:04:23.247Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-24T11:04:24.192Z"
   },
   {
    "duration": 1115126,
    "start_time": "2023-08-24T11:04:24.203Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-24T11:22:59.332Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-24T11:22:59.345Z"
   },
   {
    "duration": 48,
    "start_time": "2023-08-24T11:22:59.367Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-24T11:22:59.417Z"
   },
   {
    "duration": 138,
    "start_time": "2023-08-24T11:22:59.422Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.562Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.564Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.566Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.570Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.573Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.575Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.576Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.577Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.580Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.581Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.582Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.584Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.584Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-24T11:22:59.585Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-24T11:25:22.353Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-24T11:25:24.229Z"
   },
   {
    "duration": 1185523,
    "start_time": "2023-08-24T11:25:29.662Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-24T11:45:15.187Z"
   },
   {
    "duration": 104561,
    "start_time": "2023-08-24T11:45:15.193Z"
   },
   {
    "duration": 4815,
    "start_time": "2023-08-24T13:16:39.492Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-24T13:17:11.734Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
